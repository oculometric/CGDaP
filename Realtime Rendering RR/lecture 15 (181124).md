ORIGINAL ELITE ITS BEAUTIFUL

efficient rendering involves three things:
- use efficient drawing algorithms/mathematics
- make full usage of powerful hardware
- do as little rendering as possible

hardware differs a lot, not everyone has a good GPU/CPU/RAM. console can guarantee user hardware but this changes between consoles and over time. to target a lot of users, game has to be able to run under a variety of platforms/hardware. so basically point number 2 is out of the window, unless youre a modern AAA games company in which case jUsT BuY A bEtTEr GrAPhiCs cArD.

input assembler is a common stalling point/bottleneck. a lot of efficiency happens in the pixel shader and output merger by avoiding as much work as possible.

clip space is the view frustrum, spanning $\begin{bmatrix}-w...w \\ -w...w \\ 0 ...w\end{bmatrix}$ 

the GPU culls primitives automatically, triangles which are outside the view frustrum are clipped automatically.

the output merger stage happens after the pixel has already had its colour calculated. OM decides how to blend a pixel and whether it should be shown at all (based on depth, alpha, blend state).

depth buffer value is between 0 and 1. represents the projection space depth after perspective divide. used to prevent drawing of things drawn behind other things.

alpha clipping may be helpful (using `Clip()` in HLSL, or `discard`). early Z testing and a few other techniques are useful.

hidden surface determination - figure out what faces you can't see, and don't draw them (needs an algorithm which doesn't require more processing time than just drawing them would). with manifold surfaces, you can remove all faces where the dot product between normal and view direction is greater than zero (backface culling). potentially cuts triangle count by 50%. however DX11 actually doesn't use the dot product, it uses a *signed area check* to determine if the vertices are clockwise or counter-clockwise. i assume this is faster (doesn't require calculating view direction for every pixel).

DX11 clipping happens during rasterisation. pixels outside the clip plane are not drawn.

only drawn if $w > 0$.

however, you can disable the depth clipping in the rasteriser description, for instance with infinite shadow volumes.

even though the rasteriser will save wasted pixels, draw calls, vertex shader, etc are still expensive. if we can cull the entire object cheaply on the CPU, then that's cool.

broadphase culling involves ruling out objects that definitley cannot be in the view. may be done by checking if an object is behind the camera (using dot product), too far away, we can discard small objects very cheaply, and not carry them forward.

$A \cdot B = |A||B|\cos \theta$

then we do narrowphase culling, by testing points on the object against the frustrum planes, we can check in more detail if an object is inside the frustrum and whether it should be drawn.

terrain has its own culling techniques. if its just one object, you have to draw it all which is bad. usually split into regular chunks, and those chunks can be culled with heuristics. the splitting can be done with a tesseleation shader.