a texture is an image, a 2d array of values.
UV coordinates are used to target a position in a texture. UV coordinates map the range 0-1 in each axis from the bottom left corner to the top right corner. this defines where vertices are on the texture and thus which texels occur where on the triangle.

there are 4 texture addressing modes:
- wrap/tile - repeat texture across surface
- mirror - repeat and reverse texture
- clamp - clamp coordinate to edge of texture
- border - fill any texels outside the bounds of the texture with a colour

unwrapping involves making a 'net' of a 3D mesh in order to flatten it onto a 2D texture. often involves compromises between minimising stretching/seams and reducing wasted texture area.

textures are nearly always square. graphics cards only really like to handle square, power-of-two sized textures. it also makes mipmapping much simpler and faster.

texture filtering is needed to solve problems of minification (one screen pixel covers multiple texture texels) and magnification (one texture texel covers multiple screen pixel).

filters (in order of performance to quality):
- point filtering (nearest) - just sample the nearest texel
	- results in pixelation when magnified, and aliasing (moire-ing) when minified
	- only requires one texture sample
	- useful for stylised rendering and UI elements
	- trilinear filtering samples texels between multiple mipmaps (avoids effects where the transition between mips is visible)
- linear (bilinear, trilinear) - sample neighbouring pixels and blend between them
	- average of 4 surrounding texels (for bilinear), interpolated in both dimensions
	- less pixelated but can cause distortions due to the interpolation
	- still quite cheap
- anisotropic - generates transformed versions of the texture scaled non-uniformly in order to preserve details in the distance or at oblique angles. much more expensive both memory-wise and computation-wise

MIP actually stands for 'multum in parvo' (many things in a small place).
mipmapping involves pre-filtering a texture and keeping downscaled-by-half versions of it. does increase memory usage (bounded at 133% of the original usage) but can significantly improve performance since MIPs can be sampled once rather than sampling the original texture 4 times for linear filtering.

textures can contain anything! not just colour. they might contain depth, shadow/environment maps, normal/displacement maps, or anything really.

we can use a normal map to disturb the normal of the surface in more detail, but this requires some math.

physically based rendering is used in high fidelity graphics aiming to replicate the physics of light. this means preserving energy when light interacts with surfaces, making use of BRDFs (Bidirectional Reflectance Distribution Functions).