low level optimisation
- compilers optimise your code at compile time
- different systems and architectures may require different optimisations
- some software-level (i.e. us) optimisations may negate the effects of compiler and CPU-level optimisations
- CPU may have multiple cores each of which may have 1 or 2 logical processors
	- the operating system performs time slicing to split time between threads
	- you can instance multiple threads to use these other cores in parallel
	- if you want to get the most out of the CPU don't use more threads than there are logical processors, as you'll just introduce time-slicing overhead
- GPU is optimised for many simple floating point operations in parallel, while CPU is optimised for performing more sequential, often more complex instructions
- reducing the number of memory fetches required
- minimise redundant code
	- unnecessary assignments or comparisons
	- repeatedly recalculating the same thing
	- frequently deleting and reinstantiating objects (there are overheads for this), use object pools
- use the minimum width of type necessary, but don't convert between types too often
- DRY - don't repeat yourself, not WET - write everything twice

high level optimisation
- choosing/designing a more efficient algorithm to perform a task
- choosing the right data structure which can be searched or traversed efficiently, depending on how they will be used
- visibility culling, or other methods of not doing calculations you don't actually need to
- LODs and draw distances

common bottlenecks
- memory accesses (contiguous memory is better, fewer cache misses)
- function calls (small functions should be inlined to minimise stack usage)
- conditional branches (if and less so switch)
- instruction execution
- data transfer
- understanding processor and system architecture can help a lot

function calls
- calling a function involves calculating the address to jump to, storing the return address and parameters on the stack, and allocating local variables
- nested function calls are limited by the maximum stack depth
- need to balance between having smaller, more modular functions and larger, more efficient (fewer function calls needed) functions
- passing by reference rather than by value, so less stuff has to be put on the stack
- some compilers will optimise for leaf functions (i.e. which don't call other functions)

conditional chains
- if..else chains lead to many jumps, control will jump between statements
- switch statements are more efficient as they will likely only use a few jumps to find the right result (and may have better branch prediction)
- switch statements use a lookup table of addresses to jump to for different conditions

loops
- static length loops will often be unrolled by the compiler
- however, unrolled loops might lead to cache misses

instruction execution time, worst to best
- exponent, log, trig
- sqrt
- modulo
- divide
- multiply
- add, subtract
- divide by power of 2 (left/right shift)
- mod by power of 2

instruction sets
- CISC vs RISC
- compilers are very good at optimising at the instruction level
- compilers will replace multiplications with additions/subtractions and left/right shifts where possible
- translating complex expressions into two or three address statements (what?)

rate of data transfer
- the wider they are, the more data can be transmitted at once
- aligning data to word boundaries is useful


> optimise, but premature optimisation is the root of all evil
> look for critical code and optimise it
> balance between maintainability, and time and space complexity

