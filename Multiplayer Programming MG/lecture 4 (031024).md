processes have different states: new (being created), running (actively executing instructions), waiting (waiting on some external event trigger), ready (waiting to run/have time on the CPU), terminated (finished execution)

there are different schedulers:
- long-term/job scheduler selects which processes should enter the ready queue, controls the degree of concurrency (?) and invoked on the order of seconds or minutes
- short-term/CPU scheduler selects which process should get execution time next and allocates available CPU time. invoked on the order of milliseconds, must be very optimised. attempts to optimise selection for throughput, slowdown, and average response time. slowdown is a normalised queueing delay without respect to execution time.

scheduling disciplines
- performance metrics:
	- throughput - amount of work to be finished in a time unit
	- utilisation - fraction of a system that is busy with useful work
	- turnaround time - time from start to completion (including waiting for things to be loaded into memory, waiting in the ready queue, execution time, blocked time waiting for an IO event, etc)
- response time - time from the arrival of a request to the time its response is produced
- waiting time - delay time in the ready queue, impacted by the metrics being optimised for
- fairness - each process thread given a fair share of available resources
- deadline - ensure processes don't wait for CPU time endlessly

bursts are periods of activity, either on the CPU side, or the IO side. CPU-bound processes usually have extended CPU bursts with very little IO, vice versa for IO-bound processes.

preemptive scheduling is where a program is forced to give up the CPU to the next process, while non-preemptive scheduling includes transitions like the program waiting for an IO event, or the application terminating. preemptive really just means the program does not give up control voluntarily. the bulk of scheduling is preemptive.

some examples of scheduling algorithms:
- First come first served - CPU executes job that arrived first
- shortest job first - CPU executes job with shortest estimated time to completion
	- minimises wait time and response time
	- may be preemptive or non-preemptive
	- works on an estimation of how long the processes' next CPU burst will be
	- only effective if this estimation is accurate
- priority scheduling - CPU executes process with highest priority
	- allocated to highest priority process first
	- priorities may be based on internal resource history or external manual config
	- when preemptive, executing program will be interrupted when a program of the same priority with a shorter CPU burst length arrives
	- no significant advantage over FCFS but ensures active/important processes get more execution time than background threads just ticking over
	- however, not fair, and starvation is possible, low priority processes might never have a chance to execute
- round robin - similar to FCFS but with limited slices of time before moving onto the next application
	- FCFS with preemption basically
	- after a certain amount of time has elapsed, the executing process will be swapped out and sent to the back of the queue
	- very common technique
	- very fair
- multi level queue - similar to RR but with multiple queues for processes with different priority levels
- multi level feedback queue - similar to MLQ but jobs can move between queues

this becomes more complex when there are more than one CPUs available. ready process queues may be per-processor or shared between all processors.

multiprocessing may be symmetric or asymmetric, where asymmetric processing involves dedicating some processors to specifically handle IO tasks, specifically handle system management/kernel tasks, etc. this reduces data sharing and may reduce scheduler overhead.